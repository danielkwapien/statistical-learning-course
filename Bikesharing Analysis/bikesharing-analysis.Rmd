---
title: "Analysis of Bikesharing Usage"
subtittle: "Classification and Model Creation"
author: "Daniel Kwapien"
date: "18-12-2022"
always_allow_html: true
output:
  html_document:
    theme: united 
    toc: true
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(MASS)
library(caret)
library(e1071)
library(GGally)
library(mice)
library(EnvStats)
library(plotly)
library(MetBrewer)
library(pROC)
library(olsrr)
colors = met.brewer('Benedictus')
```

# 1. Motivation

Bikesharing is a widespread system used in a lot of cities around the globe. In this shared transport service, bicycles are available for shared use by individuals at low cost. Currently rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes. This data set is provived by the Seoul Government and it contains weather information, the number of bikes rented per hour and date information.

We will be trying to predict, given the information from the dataset, the demand using a classification model and the exact number of bikes using a regression model.

```{r}
data=read.csv(file="SeoulBikeData.csv",
              header=T,sep=",",dec=".", fileEncoding = "ISO-8859-1", stringsAsFactors = TRUE)
glimpse(data)
```


The variables from left to right, are:

Input variables: 

1. Date : year-month-day
3. Hour - Hour of he day
4. Temperature-Temperature in Celsius
5. Humidity - %
6. Windspeed - m/s
7. Visibility - 10m
8. Dew point temperature - Celsius
9. Solar radiation - MJ/m2
10. Rainfall - mm
11. Snowfall - cm
12. Seasons - Winter, Spring, Summer, Autumn
13. Holiday - Holiday/No holiday
14. Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)

Output variable:

2. Rented Bike count - Count of bikes rented at each hour

# 2. Data preprocessing and visualization

## 2.1. Data Preprocessing

### 2.1.1. Missing values

```{r}
sum(is.na(data))
```

We have no missing values, so we will insert them and see how we would deal with them

Now we have 876 missing values

```{r}
sum(is.na(data$Rented.Bike.Count))
```

From which 68 are missing RentedBikeCount's. We can't impute these, since that is the goal of our model, so we will directly remove them.

```{r}
data = data[complete.cases(data$Rented.Bike.Count), ]
```

For the other missing values, we could impute them using the mice library random forest model.


### 2.1.2. Outliers 

We have to remove those instances where $RBC< 1$ (RBC: Rented Bike Count)

```{r}
data = data[data$Rented.Bike.Count >= 1,]
```

Then, we will deal with the outliers using the *3-sigma-rule*

```{r}
for(i in seq(from =4, to = 11)){
  mu <- mean(data[,i])
  sigma <- sd(data[,i])
  data = subset(data, data[,i] > mu - 3*sigma & data[,i] < mu + 3*sigma)
  }
dim(data)
```

We are left with ~8000 instances.

### 2.1.3. Feature engineering

It seems that we don't need a lot of feature engineering, since the variables data set are in the units we are looking to work with. 

We will create a new categorical variable called *Demand* which will be based on *Rented Bike Count*. *Demand* will have 3 levels: 

* LowDemand: $RBC < 200$

* RegularDemand: $200 \leq RBC < 1100$

* HighDemand: $RBC \geq 1100$

($RBC$ stands for *Rented Bike Count*)

The limits of each level are based on the quantiles of *Rented Bike Count*


```{r}
summary(data$Rented.Bike.Count)
```

```{r}
data$Demand = case_when(
  data$Rented.Bike.Count < 200 ~ 'LowDemand',
  data$Rented.Bike.Count >= 200 & data$Rented.Bike.Count < 1100 ~ 'RegularDemand',
  data$Rented.Bike.Count >= 1100 ~ 'HighDemand'
)
```

And of course, remove the date and FunctioningDay variables, which we don't need

```{r}
data = data[,-c(1,14)]
```

```{r}
head(data)
```

This the data matrix we will be making our models with.

### 2.1.5. Data splitting

First, we need to fix the following bug:

```{r}
levels(data$Demand)
```

I will fix this by:

```{r}
for(i in c(2,11,12,13)){
  data[,i] = as.factor(data[,i])
}
levels(data$Demand)
```

And the bug would be fixed.


Since we will be creating a classification and a regression model, we need to split our data set into a train set and a test set

```{r}
spl = createDataPartition(data$Rented.Bike.Count, p = 0.8, list = FALSE)  # 80% for training

train = data[spl,]
test = data[-spl,]
```



## 2.2. Exploratory Data Analysis

```{r}
plot_ly(x = train$Rented.Bike.Count, type = "histogram", color = I(colors[1]))
```

We can see that in *Rented Bike Count* the peak is around 100 bikes, and then it has a lot of variance.

```{r}
ggcorr(train, label = T, label_size = 3, low = colors[1], high = colors[13], midpoint = 0)
```

We can see that, overall, variables do not have a lot of correlation, except dew point temperature, which correlated with temperature and humidity, but we won't remove it. *Rented Bike Count* is correlated the most with temperature, we should plot it to see the relation.

```{r}
ggplot(train, aes(x=Temperature..C., y=sqrt(Rented.Bike.Count))) + ylab("price") + 
  geom_point(alpha=0.6) + ggtitle("Rented Bike Count vs Temperature")
```

Seems like applying a square-root transformation to *Rented Bike Count* makes the relation with *Temperature* somehow linear. This will be useful for our regression model.

Then, we should visualize all of our numeric variables.

```{r}
par(mfrow= c(3,3))
for(i in c(1,3,4,5,6,7,8,9,10)){
  boxplot(train[,i], las=2, xlab = colnames(train)[i], col = colors[1])
}
```

The Rainfall and Snowfall boxplots look a little bit strange, but it makes sense taking into account the different seasons, since the data was measured during an entire year.

Finally, we can plot a pie chart showing how much traffic (*Rented Bike Count*) belongs to each demand period.

```{r}
plot_ly(train, labels = ~Demand, values = ~Rented.Bike.Count, type = 'pie', colors = I(colors))
```

We can see that 56% of bikes were rented during a high demand period, but on the other hand a 40% of bikes were rented during a normal demand period. Only 3.5% of bikes were rented during de Low Demand period

# 3. Classification

We will be try to predict to which level of demand will belong a certain class. So, for now, we will remove *Rented Bike Count*

```{r}
train = train[,-c(1)]
test = test[,-c(1)]
```


## 3.1. Linear Discriminant Analysis (LDA)

Since, we have 3 groups, we can't use a logistic regression, so I will go with a Linear Discriminant Analysis in order to make a classification model because we can assume that each group has the same covariance matrix, so we will save computing power. 


```{r}
lda.model <- lda(Demand ~ ., data=train)

lda.model
```

```{r}
prediction = predict(lda.model, newdata=test)$class
probability = predict(lda.model, newdata=test)$posterior
```

```{r}
confusionMatrix(prediction, test$Demand)$table
```
```{r}
confusionMatrix(prediction, test$Demand)$overall[1]
```


# 4. Regression

Remember that we remove *Rented Bike Count*, so we have to recover it, and now remove *Demand*

```{r}
data$Seasons = factor(data$Seasons, 
				 levels = c('Autumn', 'Spring', 'Summer', 'Winter'),
				 labels = c(1, 2, 3, 4))
data$Holiday = factor(data$Holiday, 
				 levels = c('Holiday', 'No Holiday'),
				 labels = c(1, 0))

train = data[spl,]
test = data[-spl,]
train = train[,-c(14)]
test = test[,-c(14)]
```

## 4.1. Simple regression

```{r}
corr_count <- sort(cor(train[,c(3,4,5,7,8,9,10)])[1,], decreasing = T)
corr=data.frame(corr_count)
ggplot(corr,aes(x = row.names(corr), y = corr_count)) + 
  geom_bar(stat = "identity", fill = colors[13]) + 
  scale_x_discrete(limits= row.names(corr)) +
  labs(x = "Predictors", y = "Price", title = "Correlations") + 
  theme(plot.title = element_text(hjust = 0, size = rel(1.5)),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

So let's try to make a simple regression model using *Temperature*

```{r}
linFit <- lm(sqrt(Rented.Bike.Count) ~ Temperature..C., data=train)
summary(linFit)
```

```{r}
par(mfrow=c(2,2))
plot(linFit, pch=23 ,bg=colors[13],cex=2)
```

```{r}
pr.simple = (predict(linFit, newdata=test))^2
cor(test$Rented.Bike.Count, pr.simple)^2
```

As low as we could expect.

## 4.2. Multiple Regression

We will make a multiple regression model using all of our variables

```{r}
linFit <- lm(sqrt(Rented.Bike.Count) ~ Hour + Temperature..C. + Humidity... + Wind.speed..m.s. + Visibility..10m. + Dew.point.temperature..C. + Solar.Radiation..MJ.m2. + Rainfall.mm. + Snowfall..cm. + Seasons + Holiday, data=train)
summary(linFit)
```

```{r}
pr.multiple = (predict(linFit, newdata=test))^2
cor(test$Rented.Bike.Count, pr.multiple)^2
```

```{r}
model = sqrt(Rented.Bike.Count) ~ Hour + Temperature..C. + Humidity... + Wind.speed..m.s. + Visibility..10m. + Dew.point.temperature..C. + Solar.Radiation..MJ.m2. + Rainfall.mm. + Snowfall..cm. + Seasons + Holiday

linFit <- lm(model, data=train)

all_predictors = ols_step_all_possible(linFit)

head(all_predictors[order(-all_predictors$rsquare),])
```
 
 These are all possible subset regressions: the number is exponential with p, from which we can see which one is the best regression model is for Adjusted R-Square
 
```{r}
all_predictors[all_predictors$adjr == max(all_predictors$adjr),]
```

```{r}
plot(ols_step_forward_aic(linFit)) # forward based on AIC
```

```{r}
plot(ols_step_backward_aic(linFit)) # backward AIC
```

Definitely, we will stack with the model we said

## 4.3. Learning Tools

We will use the model we said, and repeated cross validation for testing

```{r}
model = sqrt(Rented.Bike.Count) ~ Hour + Temperature..C. + Humidity... + Wind.speed..m.s. + Visibility..10m. + Dew.point.temperature..C. + Solar.Radiation..MJ.m2. + Rainfall.mm. + Snowfall..cm. + Seasons + Holiday
ctrl <- trainControl(method = "repeatedcv", 
                     number = 5, repeats = 1)
```

```{r}
linFit <- lm(model, data=train)

summary(linFit)
```

We get a R2 of 75%, which is actually really good. 

```{r}
test_results <- data.frame(Rented.Bike.Count = sqrt(test$Rented.Bike.Count))
```

### 4.3.1. Linear regression

```{r}
lm_tune <- train(model, data = train, 
                 method = "lm", 
                 preProc=c('scale', 'center'),
                 trControl = ctrl)
lm_tune
```

```{r}
test_results$lm <- predict(lm_tune, test)
postResample(pred = test_results$lm,  obs = test_results$Rented.Bike.Count)
```

### 4.3.2. Stepwise regression

```{r}
step_tune <- train(model, data = train, 
                   method = "leapSeq", 
                   preProc=c('scale', 'center'),
                   tuneGrid = expand.grid(nvmax = 4:10),
                   trControl = ctrl)
plot(step_tune)
```

```{r}
test_results$seq <- predict(step_tune, test)
postResample(pred = test_results$seq,  obs = test_results$Rented.Bike.Count)
```

### 4.3.3. The Lasso

```{r}
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 100))

lasso_tune <- train(model, data = train,
                    method='lasso',
                    preProc=c('scale','center'),
                    tuneGrid = lasso_grid,
                    trControl=ctrl)
plot(lasso_tune)
```

```{r}
lasso_tune$bestTune
```

```{r}
test_results$lasso <- predict(lasso_tune, test)
postResample(pred = test_results$lasso,  obs = test_results$Rented.Bike.Count)
```


### 4.3.4. Elastic Net

```{r}
elastic_grid = expand.grid(alpha = seq(0, .2, 0.01), lambda = seq(0, .1, 0.01))

glmnet_tune <- train(model, data = train,
                     method='glmnet',
                     preProc=c('scale','center'),
                     tuneGrid = elastic_grid,
                     trControl=ctrl)

plot(glmnet_tune)
```

```{r}
glmnet_tune$bestTune
```

```{r}
test_results$glmnet <- predict(glmnet_tune, test)

postResample(pred = test_results$glmnet,  obs = test_results$Rented.Bike.Count)
```

### 4.3.5. k-Nearest-Neighbors

```{r}
knn_tune <- train(model, 
                  data = train,
                  method = "kknn",   
                  preProc=c('scale','center'),
                  tuneGrid = data.frame(kmax=c(11,13,15,19,21),distance=2,kernel='optimal'),
                  trControl = ctrl)
plot(knn_tune)
```

```{r}
test_results$knn <- predict(knn_tune, test)

postResample(pred = test_results$knn,  obs = test_results$Rented.Bike.Count)
```

### 4.3.6. Overview

```{r}
apply(test_results[-1], 2, function(x) mean(abs(x - test_results$Rented.Bike.Count)))
```

We get a pretty high RMSE, but our R2 is quiet good.

## 4.4. Final Predictions

```{r}
yhat = (test_results$knn)^2

hist(yhat, col=colors[1])
```

As we can see, the histogram of $\hat{y}$ look pretty similar like the original $y$

```{r}
y = (test_results$Rented.Bike.Count)^2
error = y-yhat
hist(error, col=colors[13])
```

Well, we can see that the overall result is good, but sometimes we get quite high errors...

Since kNN do not provide prediction intervals, we can split the testing set in two parts: one to measure the size of the noise, and the other one to compute the intervals from that size

Let’s use the first 100 counts in test set to compute the noise size

```{r}
noise = error[1:100]
lwr = yhat[101:length(yhat)] + quantile(noise,0.05, na.rm=T)
upr = yhat[101:length(yhat)] + quantile(noise,0.95, na.rm=T)
predictions = data.frame(real=y[101:length(y)], fit=yhat[101:length(yhat)], lwr=lwr, upr=upr)
predictions = predictions %>% mutate(out=factor(if_else(real<lwr | real>upr,1,0)))

ggplot(predictions, aes(x=fit, y=real))+
  geom_point(aes(color=out)) + theme(legend.position="none") +
  geom_ribbon(data=predictions,aes(ymin=lwr,ymax=upr),alpha=0.3) +
  labs(title = "Prediction intervals", x = "prediction",y="real price")
```

## 4.5. Conclusions

So we can conclude that our best model for regression is using all the 10 variables and optimizing it with kNN to get the best adjusting. For this adjusting we get a quite RMSE but a fairly good R2
